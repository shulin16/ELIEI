#### general settings
name: IR_small_qat
use_tb_logger: true
model: LLFlow
distortion: sr
scale: 1
gpu_ids: [0]
dataset: IR_Dataset
optimize_all_z: false
cond_encoder: ConEncoder1
train_gt_ratio: 0.2
avg_color_map: false
concat_histeq: true
histeq_as_input: false
concat_color_map: false
gray_map: false # concat 1-input.mean(dim=1) to the input

align_condition_feature: false
align_weight: 0.001
align_maxpool: true

to_yuv: false

encode_color_map: false
le_curve: false
# sigmoid_output: true

#### datasets
datasets:
  train:
    root: /home/Dataset/DatasetYufei/IR-RGB-Dataset-resize  # data root
    quant: 32
    use_shuffle: true
    n_workers: 1  # per GPU
    batch_size: 16
    use_flip: true
    color: RGB
    use_crop: true
    GT_size: 160 # 192
    noise_prob: 0
    noise_level: 5
    log_low: true
    gamma_aug: false

  val:
    root: /home/Dataset/DatasetYufei/IR-RGB-Dataset-resize
    n_workers: 1
    quant: 32
    n_max: 20
    batch_size: 1 # must be 1
    log_low: true

#### Test Settings

dataroot_GT: /home/Dataset/DatasetYufei/IR-RGB-Dataset-resize/eval/high
dataroot_LR: /home/Dataset/DatasetYufei/IR-RGB-Dataset-resize/eval/low
heat: 0 # This is the standard deviation of the latent vectors
# dataroot_unpaired: /home/data/Dataset/LOL_test/Fusion
model_path: 


#### network structures
network_G:
  which_model_G: LLFlow
  in_nc: 3
  out_nc: 3
  nf: 32   ###### smallNet ######
  nb: 4 #  12 for our low light encoder, 23 for LLFlow  ###### smallNet ######
  train_RRDB: false
  train_RRDB_delay: 0.5

  flow:
    K: 4 # 24.49 psnr用的12 # 16
    L: 3 # 4
    noInitialInj: true
    coupling: CondAffineSeparatedAndCond
    additionalFlowNoAffine: 2
    conditionInFeaDim: 64
    split:
      enable: false
    fea_up0: true
    stackRRDB:
      blocks: [1]
      concat: true

#### path
path:
  # pretrain_model_G: ../pretrained_models/RRDB_DF2K_8X.pth
  strict_load: true
  resume_state: auto

#### training settings: learning rate scheme, loss
train:
  manual_seed: 10
  lr_G: !!float 5e-4 # normalizing flow 5e-4; l1 loss train 5e-5
  weight_decay_G: 0 # 1e-5 # 5e-5 # 1e-5
  beta1: 0.9
  beta2: 0.99
  lr_scheme: MultiStepLR
  warmup_iter: -1  # no warm up
  lr_steps_rel: [ 0.5, 0.75, 0.9, 0.95 ] # [0.2, 0.35, 0.5, 0.65, 0.8, 0.95]  # [ 0.5, 0.75, 0.9, 0.95 ]
  lr_gamma: 0.5
  EMD: true

  weight_l1: 0
  # flow_warm_up_iter: -1
  weight_fl: 1
  weight_emd: !!float 1e-2

  niter: 10000  #30000 #200000
  val_freq:  2  # 200

#### validation settings
val:
  # heats: [ 0.0, 0.5, 0.75, 1.0 ]
  n_sample: 4

test:
  heats: [ 0.0, 0.7, 0.8, 0.9 ]

#### logger
logger:
  # Debug print_freq: 100
  print_freq: 100
  save_checkpoint_freq: !!float 1e3




# ###MIR###
# # Optimization arguments.
# OPTIM:
#   BATCH_SIZE: 16
#   NUM_EPOCHS: 300
#   LR_INITIAL: 2e-4
#   #NEPOCH_DECAY: [40]
#   #BETA1: 0.9

# TRAINING:
#   TRAIN_PS: 196
#   VAL_PS: 196
#   RESUME: False
#   TRAIN_DIR: '/home/yufei/shulin/LLFlow/IR-RGB-Dataset-resize/train' # path to training data
#   VAL_DIR: '/home/yufei/shulin/LLFlow/IR-RGB-Dataset-resize/eval'     # path to validation data
#   SAVE_DIR: '/home/yufei/project2022/LLFlow/results/mir/train'          # path to save models and images
#   SAVE_FREQ: 50
#   SAVE_IMAGES: true
#   GENERATE_GT: true


# TESTING:
